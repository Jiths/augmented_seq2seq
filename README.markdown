# Augmented Seq2seq

- [ ] Vanilla Seq2seq
- [ ] Language Modeling with encoder
- [ ] Bidirectional encoder
- [ ] RNNSearch : Soft Alignment
- [ ] Conditioning decoder on external context
- [ ] Memory augmentation
- [ ] Multi-turn Conversation Modeling with Hierarchical Recurrent Encoder-Decoder (HRED)

## Reference

1. Ed Grefenstette, *Beyond Sequence to Sequence with Augmented RNNs* [video](https://www.youtube.com/watch?v=4deLk3Eu05E), [slides](http://videolectures.net/site/normal_dl/tag=1051689/deeplearning2016_grefenstette_augmented_rnn_01.pdf)
2. [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
3. [End-to-End Memory Networks](https://arxiv.org/abs/1503.08895)
4. [Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models](https://arxiv.org/abs/1507.04808)
